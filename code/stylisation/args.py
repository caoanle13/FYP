optimizer = "lbfgs" # options: ['lbfgs', 'adam']
init_noise_ratio = 0.0 # ranging from 0.0 to 1.0
model_path = 'stylisation/imagenet-vgg-verydeep-19.mat' #path to vgg model
feature_pooling_type = 'avg' # options: ['avg', 'max'], poolying type of the vgg model
mask_downsample_type = 'simple' # options: ['simple', 'all', 'inside', 'mean'], how to propagate masks to different layers
content_layers = ['relu4_2'] # VGG19 layers used for the content image
content_layers_weights = [1.] # weights of each content layer
style_layers = ['relu1_1', 'relu2_1', 'relu3_1', 'relu4_1', 'relu5_1'] # VGG19 layers used for the style image
style_layers_weights = [1., 1., 1., 1., 1.] # weights of each style layer
content_loss_normalization = 1 # options: [1, 2], 1 for 1./(N * M); 2 for 1./(2. * N**0.5 * M**0.5)
mask_normalization_type = 'square_sum' # options: ['square_sum', 'sum'], How to normalize a masked gram matrix
content_weight = 1. # Content loss weight
style_weight = 0.2 # style loss weight
tv_weight = 0. # Total variation loss weight
optimizer = 'lbfgs' # options: ['lbfgs', 'adam']
learning_rate = 10. # learning rate for adam optimizer
iteration = 800 # max iteration of training
log_iteration = 10 # Number of iterations to print loss. For adam, also save intermediate result. For L-BFGS, don\'t larger than 10